{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import pickle\n",
    "import json\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from DirectoryIteratorWithBoundingBoxes import DirectoryIteratorWithBoundingBoxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /Users/costanzasiniscalchi/Documents/MS/DLCV/Sheet-Music-Parser/ModelTrainer/datasets\n"
     ]
    }
   ],
   "source": [
    "# Current working directory\n",
    "cwd = os.getcwd()\n",
    "print(\"Current Working Directory:\", cwd)\n",
    "\n",
    "# Base path\n",
    "base_path = os.path.join(cwd, \"data\", \"data\", \"muscima_split\")\n",
    "\n",
    "# Correct paths for train, val, and test splits\n",
    "train_xml_directory = os.path.join(base_path, \"train\", \"annotations\")\n",
    "train_img_directory = os.path.join(base_path, \"train\", \"sheet_music\")\n",
    "train_output_path = os.path.join(base_path, \"train\", \"bounding_boxes.pkl\")\n",
    "\n",
    "val_xml_directory = os.path.join(base_path, \"val\", \"annotations\")\n",
    "val_img_directory = os.path.join(base_path, \"val\", \"sheet_music\")\n",
    "val_output_path = os.path.join(base_path, \"val\", \"bounding_boxes.pkl\")\n",
    "\n",
    "test_xml_directory = os.path.join(base_path, \"test\", \"annotations\")\n",
    "test_img_directory = os.path.join(base_path, \"test\", \"sheet_music\")\n",
    "test_output_path = os.path.join(base_path, \"test\", \"bounding_boxes.pkl\")\n",
    "\n",
    "json_path = os.path.join(cwd,'MUSCIMA_class_splits.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'sheet_music'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 51\u001b[0m\n\u001b[1;32m     48\u001b[0m classes \u001b[38;5;241m=\u001b[39m get_classes_from_json(json_path)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Initialize Datasets\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDirectoryIteratorWithBoundingBoxes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_img_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbounding_boxes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_bboxes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcategorical\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m DirectoryIteratorWithBoundingBoxes(\n\u001b[1;32m     61\u001b[0m     directory\u001b[38;5;241m=\u001b[39mval_img_directory,\n\u001b[1;32m     62\u001b[0m     bounding_boxes\u001b[38;5;241m=\u001b[39mval_bboxes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m     classes\u001b[38;5;241m=\u001b[39mclasses\n\u001b[1;32m     67\u001b[0m )\n\u001b[1;32m     69\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m DirectoryIteratorWithBoundingBoxes(\n\u001b[1;32m     70\u001b[0m     directory\u001b[38;5;241m=\u001b[39mtest_img_directory,\n\u001b[1;32m     71\u001b[0m     bounding_boxes\u001b[38;5;241m=\u001b[39mtest_bboxes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     75\u001b[0m     classes\u001b[38;5;241m=\u001b[39mclasses\n\u001b[1;32m     76\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/MS/DLCV/Sheet-Music-Parser/ModelTrainer/datasets/DirectoryIteratorWithBoundingBoxes.py:38\u001b[0m, in \u001b[0;36mDirectoryIteratorWithBoundingBoxes.__init__\u001b[0;34m(self, directory, bounding_boxes, target_size, transform, class_mode, classes)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses:\n\u001b[1;32m     37\u001b[0m     class_label \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(root)\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_to_idx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclass_label\u001b[49m\u001b[43m]\u001b[49m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sheet_music'"
     ]
    }
   ],
   "source": [
    "# Check if paths exist\n",
    "for path in [train_output_path, val_output_path, test_output_path]:\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"File not found: {path}\")\n",
    "        raise FileNotFoundError(f\"The file {path} does not exist. Check your paths.\")\n",
    "\n",
    "# Load bounding boxes\n",
    "with open(train_output_path, 'rb') as f:\n",
    "    train_bboxes = pickle.load(f)\n",
    "\n",
    "with open(val_output_path, 'rb') as f:\n",
    "    val_bboxes = pickle.load(f)\n",
    "\n",
    "with open(test_output_path, 'rb') as f:\n",
    "    test_bboxes = pickle.load(f)\n",
    "\n",
    "\n",
    "def extract_classes_from_bboxes(bbox_dict):\n",
    "    \"\"\"\n",
    "    Extract unique class labels from bounding box annotations.\n",
    "\n",
    "    Args:\n",
    "        bbox_dict (dict): Bounding box dictionary with filenames as keys and annotations.\n",
    "\n",
    "    Returns:\n",
    "        list: Sorted list of unique class labels.\n",
    "    \"\"\"\n",
    "    class_set = set()\n",
    "    for filename, annotations in bbox_dict.items():\n",
    "        # Each annotation may have a 'class' or 'label' field\n",
    "        if 'class' in annotations:\n",
    "            class_set.add(annotations['class'])\n",
    "        elif 'label' in annotations:\n",
    "            class_set.add(annotations['label'])\n",
    "    return sorted(class_set)\n",
    "\n",
    "# Example: Load the bounding box annotations\n",
    "with open(\"train_bounding_boxes.pkl\", \"rb\") as f:\n",
    "    train_bboxes = pickle.load(f)\n",
    "\n",
    "# Extract the classes\n",
    "classes = extract_classes_from_bboxes(train_bboxes)\n",
    "print(\"Extracted classes:\", classes)\n",
    "all_classes)\n",
    "    return class_list\n",
    "\n",
    "# Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Classes (example)\n",
    "classes = extract_classes_from_bboxes(train_bboxes)\n",
    "\n",
    "# Initialize Datasets\n",
    "train_dataset = DirectoryIteratorWithBoundingBoxes(\n",
    "    directory=train_img_directory,\n",
    "    bounding_boxes=train_bboxes,\n",
    "    target_size=(256, 256),\n",
    "    transform=transform,\n",
    "    class_mode=\"categorical\",\n",
    "    classes=classes\n",
    ")\n",
    "\n",
    "val_dataset = DirectoryIteratorWithBoundingBoxes(\n",
    "    directory=val_img_directory,\n",
    "    bounding_boxes=val_bboxes,\n",
    "    target_size=(256, 256),\n",
    "    transform=transform,\n",
    "    class_mode=\"categorical\",\n",
    "    classes=classes\n",
    ")\n",
    "\n",
    "test_dataset = DirectoryIteratorWithBoundingBoxes(\n",
    "    directory=test_img_directory,\n",
    "    bounding_boxes=test_bboxes,\n",
    "    target_size=(256, 256),\n",
    "    transform=transform,\n",
    "    class_mode=\"categorical\",\n",
    "    classes=classes\n",
    ")\n",
    "\n",
    "# Initialize DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Test DataLoader\n",
    "if __name__ == \"__main__\":\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        print(\"Batch of images shape:\", batch_x.shape)\n",
    "        if isinstance(batch_y, tuple):\n",
    "            labels, bboxes = batch_y\n",
    "            print(\"Batch of labels shape:\", labels.shape)\n",
    "            print(\"Batch of bounding boxes shape:\", bboxes.shape)\n",
    "        else:\n",
    "            print(\"Batch of bounding boxes shape:\", batch_y.shape)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
